{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208e967e-28d8-4582-8ef8-db391ab0c40a",
   "metadata": {},
   "source": [
    "# 01-Pipeline - Build\n",
    "\n",
    "Write code here to generate seperate python files\n",
    "\n",
    "* [`src/pipelines/train_pipeline.py`](src/pipelines/train_pipeline.py) \n",
    "\n",
    "\n",
    "test locally with [`src/build_and_deploy.py`](src/build_and_deploy.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f8b283-0412-40b0-a2a0-6da0cb19ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/pipelines/train_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/pipelines/train_pipeline.py\n",
    "import os\n",
    "\n",
    "import kfp\n",
    "import time\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import component, pipeline, Artifact, ClassificationMetrics, Input, Output, Model, Metrics\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from typing import NamedTuple\n",
    "\n",
    "#Main pipeline class\n",
    "class pipeline_controller():\n",
    "    def __init__(self, template_path, display_name, pipeline_root, project_id, region):\n",
    "        self.template_path = template_path\n",
    "        self.display_name = display_name\n",
    "        self.pipeline_root = pipeline_root\n",
    "        self.project_id = project_id\n",
    "        self.region = region\n",
    "    \n",
    "    def _build_compile_pipeline(self):\n",
    "        \"\"\"Method to build and compile pipeline\"\"\"\n",
    "        self.pipeline = self._get_pipeline()\n",
    "        compiler.Compiler().compile(\n",
    "            pipeline_func=self.pipeline, package_path=self.template_path\n",
    "        )\n",
    "        \n",
    "        ##Write JSON file to GCS\n",
    "        \n",
    "    def _submit_job(self):\n",
    "        \"\"\"Method to Submit ML Pipeline job\"\"\"\n",
    "        #Next, define the job:\n",
    "        ml_pipeline_job = aiplatform.PipelineJob(\n",
    "            display_name=self.display_name,\n",
    "            template_path=self.template_path,\n",
    "            pipeline_root=self.pipeline_root,\n",
    "            parameter_values={\"project\": self.project_id, \"display_name\": self.display_name},\n",
    "            enable_caching=True\n",
    "        )\n",
    "\n",
    "        #And finally, run the job:\n",
    "        ml_pipeline_job.submit()\n",
    "    \n",
    "    def _get_pipeline(self):\n",
    "        \"\"\"Main method to Create pipeline\"\"\"\n",
    "        @pipeline(name=\"automl-tab-beans-training-v2\",\n",
    "                          pipeline_root=self.pipeline_root)\n",
    "        def pipeline_fn(\n",
    "            bq_source: str = \"bq://aju-dev-demos.beans.beans1\",\n",
    "            display_name: str = self.display_name,\n",
    "            project: str = self.project_id,\n",
    "            gcp_region: str = self.region,\n",
    "            api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "            thresholds_dict_str: str = '{\"auRoc\": 0.95}',\n",
    "        ):\n",
    "            \n",
    "            #Load all reusable custom components\n",
    "            eval_op = kfp.components.load_component('component_specs/classification_eval_model_v2.yaml')\n",
    "\n",
    "            #Start pipeline formation\n",
    "            dataset_create_op = gcc_aip.TabularDatasetCreateOp(\n",
    "                project=project, display_name=display_name, bq_source=bq_source\n",
    "            )\n",
    "\n",
    "            training_op = gcc_aip.AutoMLTabularTrainingJobRunOp(\n",
    "                project=project,\n",
    "                display_name=display_name,\n",
    "                optimization_prediction_type=\"classification\",\n",
    "                budget_milli_node_hours=1000,\n",
    "                column_transformations=[\n",
    "                    {\"numeric\": {\"column_name\": \"Area\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"Perimeter\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"MajorAxisLength\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"MinorAxisLength\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"AspectRation\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"Eccentricity\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"ConvexArea\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"EquivDiameter\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"Extent\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"Solidity\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"roundness\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"Compactness\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"ShapeFactor1\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"ShapeFactor2\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"ShapeFactor3\"}},\n",
    "                    {\"numeric\": {\"column_name\": \"ShapeFactor4\"}},\n",
    "                    {\"categorical\": {\"column_name\": \"Class\"}},\n",
    "                ],\n",
    "                dataset=dataset_create_op.outputs[\"dataset\"],\n",
    "                target_column=\"Class\",\n",
    "            )\n",
    "\n",
    "            model_eval_task = eval_op(\n",
    "                project,\n",
    "                gcp_region,\n",
    "                api_endpoint,\n",
    "                thresholds_dict_str,\n",
    "                training_op.outputs[\"model\"],\n",
    "            )\n",
    "\n",
    "            with dsl.Condition(\n",
    "                model_eval_task.outputs[\"dep_decision\"] == \"true\",\n",
    "                name=\"deploy_decision\",\n",
    "            ):\n",
    "\n",
    "                endpoint_op = gcc_aip.EndpointCreateOp(\n",
    "                    project=project,\n",
    "                    location=gcp_region,\n",
    "                    display_name=\"train-automl-beans\",\n",
    "                )\n",
    "\n",
    "                gcc_aip.ModelDeployOp(\n",
    "                    model=training_op.outputs[\"model\"],\n",
    "                    endpoint=endpoint_op.outputs[\"endpoint\"],\n",
    "                    dedicated_resources_min_replica_count=1,\n",
    "                    dedicated_resources_max_replica_count=1,\n",
    "                    dedicated_resources_machine_type=\"n1-standard-4\",\n",
    "                )\n",
    "            \n",
    "        return pipeline_fn"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
