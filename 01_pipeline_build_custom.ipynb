{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d9a97f-62b3-4340-a1ab-1554b0f8909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for this notebook to run\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import NamedTuple\n",
    "\n",
    "from google.cloud import aiplatform as vertex\n",
    "from google_cloud_pipeline_components.experimental import vertex_notification_email as gcc_exp\n",
    "\n",
    "import kfp\n",
    "from kfp.v2 import dsl, compiler\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Metrics, Output, OutputPath, component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4739ce47-f3b5-44a3-8967-1cd7f269c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "PROJECT_ID = \"your-project-id\"\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = f\"bkt-{PROJECT_ID}-vpipelines\"\n",
    "BUCKET_PATH = f\"gs://{BUCKET_NAME}\"\n",
    "PIPELINE_ROOT = f\"{BUCKET_PATH}/pipeline_root\"\n",
    "PIPELINE_DATA = f\"{BUCKET_PATH}/data\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b7711e-8707-427f-9624-04402372e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download BigQuery data and convert to CSV\n",
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\", \"db-dtypes\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"src/component_create_dataset.yaml\"\n",
    ")\n",
    "def get_dataframe(\n",
    "    bq_table: str,\n",
    "    output_data_path: OutputPath(\"Dataset\")\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    # TODO - change to be hard-coded per Google best practices \n",
    "    project_number = os.environ[\"CLOUD_ML_PROJECT_ID\"]\n",
    "    bqclient = bigquery.Client(project=project_number)\n",
    "    table = bigquery.TableReference.from_string(\n",
    "        bq_table\n",
    "    )\n",
    "    rows = bqclient.list_rows(\n",
    "        table\n",
    "    )\n",
    "    dataframe = rows.to_dataframe(\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    "    dataframe = dataframe.sample(frac=1, random_state=2)\n",
    "    dataframe.to_csv(output_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97324b60-e3b7-431e-8c51-0d5c95eb927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a component to train a Scikit-learn model\n",
    "@component(\n",
    "    packages_to_install=[\"sklearn\", \"pandas\", \"numpy\", \"db-dtypes\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"src/component_specs/component_train_model.yaml\",\n",
    ")\n",
    "def sklearn_train(\n",
    "    dataset: Input[Dataset],\n",
    "    metrics: Output[Metrics],\n",
    "    model: Output[Model]\n",
    "):\n",
    "    from numpy import mean, std\n",
    "    from sklearn.metrics import roc_curve\n",
    "    \n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "    \n",
    "    import pickle\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(dataset.path)\n",
    "    labels = df.pop(\"label\").tolist()\n",
    "    data = df.values.tolist()\n",
    "    \n",
    "    # cross validation\n",
    "    skmodel = GradientBoostingClassifier()\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(skmodel, data, labels, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    \n",
    "    # log cv metrics\n",
    "    metrics.log_metric(\"framework\", \"Scikit Learn\")\n",
    "    metrics.log_metric(\"dataset_size\", len(df))\n",
    "    metrics.log_metric(\"CV_accuracy_mean\", mean(n_scores))\n",
    "    metrics.log_metric(\"CV_accuracy_stdev\", std(n_scores))\n",
    "    \n",
    "    # fit the model on the whole dataset\n",
    "    skmodel = GradientBoostingClassifier()\n",
    "    skmodel.fit(data, labels)\n",
    "    \n",
    "    #dump(skmodel, model.path + \".joblib\")\n",
    "    with open(model.path + \".pkl\", 'wb') as model_file:\n",
    "        pickle.dump(skmodel, model_file)\n",
    "    model.uri = model.uri  + \".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07e46f2a-15b9-48d5-96ec-4bfb80cf3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a component to upload and deploy the model to Vertex AI\n",
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"src/component_specs/component_deploy_model.yaml\",\n",
    ")\n",
    "def deploy_model(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(project=project, location=region)\n",
    "\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"my-model-pipeline\"\n",
    "        , artifact_uri = model.uri.replace(\"model.pkl\", \"\")\n",
    "        , serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "\n",
    "    # Save data to the output params\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d558acb0-2743-4ec6-ae0a-dcd79748709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a pipeline\n",
    "@dsl.pipeline(name=\"deployed-model\", description=\"my pipeline description\")\n",
    "\n",
    "# specify all the inputs the pipeline needs to run\n",
    "def my_pipeline(\n",
    "    bq_table: str = \"\",\n",
    "    output_data_path: str = \"data.csv\",\n",
    "    project_id: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    \n",
    "    # notification recipients\n",
    "    RECIPIENTS_LIST = [\"your-email@your-domain.com\"]\n",
    "    notify_email_task = gcc_exp.VertexNotificationEmailOp(recipients=RECIPIENTS_LIST)\n",
    "    \n",
    "    # when pipeline exits, send status notification\n",
    "    with dsl.ExitHandler(notify_email_task):\n",
    "        \n",
    "        # specify the nodes in the pipeline\n",
    "        dataset_task = get_dataframe(bq_table)\n",
    "        \n",
    "        model_task = sklearn_train(dataset_task.output)\n",
    "        \n",
    "        deploy_task = deploy_model(\n",
    "            model=model_task.outputs[\"model\"],\n",
    "            project=PROJECT_ID,\n",
    "            region=REGION\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613aadd7-48ef-4617-8523-f38a0fa81107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the pipeline\n",
    "my_package_path = 'src/my_vertex_pipeline_specification_file.json'\n",
    "compiler.Compiler().compile(pipeline_func=my_pipeline, package_path=my_package_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb37e5c-e52b-4f50-a35e-4b01ca136e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
